{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-20T16:47:34.161462Z",
     "start_time": "2024-11-20T16:47:34.142487Z"
    }
   },
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "_ = load_dotenv()"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T16:53:49.535676Z",
     "start_time": "2024-11-20T16:53:49.515139Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from typing import TypedDict, Annotated\n",
    "import operator\n",
    "from langchain_core.messages import AnyMessage, SystemMessage, HumanMessage, ToolMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "\n"
   ],
   "id": "4424121cb06b725b",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langgraph.checkpoint.sqlite'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_openai\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ChatOpenAI\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlangchain_community\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtavily_search\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TavilySearchResults\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlanggraph\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcheckpoint\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msqlite\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SqliteSaver\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'langgraph.checkpoint.sqlite'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T16:53:40.365706Z",
     "start_time": "2024-11-20T16:53:40.079169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tool = TavilySearchResults(max_results=2)\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]\n",
    "\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "\n"
   ],
   "id": "c26e792d1636b905",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SqliteSaver' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mAgentState\u001B[39;00m(TypedDict):\n\u001B[0;32m      4\u001B[0m     messages: Annotated[\u001B[38;5;28mlist\u001B[39m[AnyMessage], operator\u001B[38;5;241m.\u001B[39madd]\n\u001B[1;32m----> 6\u001B[0m memory \u001B[38;5;241m=\u001B[39m SqliteSaver\u001B[38;5;241m.\u001B[39mfrom_conn_string(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m:memory:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'SqliteSaver' is not defined"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T16:53:19.167326Z",
     "start_time": "2024-11-20T16:53:10.857735Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install langgraph",
   "id": "addb42af739a9fd3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\giorg\\anaconda3\\lib\\site-packages (0.2.52)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langgraph) (0.3.19)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.4 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langgraph) (2.0.5)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.32 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langgraph) (0.1.36)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (6.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.1.143)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (4.11.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.4->langgraph) (1.1.0)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.26.0)\n",
      "Requirement already satisfied: httpx-sse>=0.4.0 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.4.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.10.11)\n",
      "Requirement already satisfied: anyio in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.5.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (3.4)\n",
      "Requirement already satisfied: sniffio in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (1.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.32->langgraph) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.31.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\giorg\\anaconda3\\lib\\site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43->langgraph) (1.26.16)\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-20T16:51:15.074435Z",
     "start_time": "2024-11-20T16:51:15.066794Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tools, checkpointer, system=\"\"):\n",
    "        self.system = system\n",
    "        graph = StateGraph(AgentState)\n",
    "        graph.add_node(\"llm\", self.call_openai)\n",
    "        graph.add_node(\"action\", self.take_action)\n",
    "        graph.add_conditional_edges(\"llm\", self.exists_action, {True: \"action\", False: END})\n",
    "        graph.add_edge(\"action\", \"llm\")\n",
    "        graph.set_entry_point(\"llm\")\n",
    "        self.graph = graph.compile(checkpointer=checkpointer)\n",
    "        self.tools = {t.name: t for t in tools}\n",
    "        self.model = model.bind_tools(tools)\n",
    "\n",
    "    def call_openai(self, state: AgentState):\n",
    "        messages = state['messages']\n",
    "        if self.system:\n",
    "            messages = [SystemMessage(content=self.system)] + messages\n",
    "        message = self.model.invoke(messages)\n",
    "        return {'messages': [message]}\n",
    "\n",
    "    def exists_action(self, state: AgentState):\n",
    "        result = state['messages'][-1]\n",
    "        return len(result.tool_calls) > 0\n",
    "\n",
    "    def take_action(self, state: AgentState):\n",
    "        tool_calls = state['messages'][-1].tool_calls\n",
    "        results = []\n",
    "        for t in tool_calls:\n",
    "            print(f\"Calling: {t}\")\n",
    "            result = self.tools[t['name']].invoke(t['args'])\n",
    "            results.append(ToolMessage(tool_call_id=t['id'], name=t['name'], content=str(result)))\n",
    "        print(\"Back to the model!\")\n",
    "        return {'messages': results}"
   ],
   "id": "651dfa82f2542cf4",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "prompt = \"\"\"You are a smart research assistant. Use the search engine to look up information. \\\n",
    "You are allowed to make multiple calls (either together or in sequence). \\\n",
    "Only look up information when you are sure of what you want. \\\n",
    "If you need to look up some information before asking a follow up question, you are allowed to do that!\n",
    "\"\"\"\n",
    "model = ChatOpenAI(model=\"gpt-4o\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)"
   ],
   "id": "c4bac6493b9b1a8c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "messages = [HumanMessage(content=\"What is the weather in sf?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "for event in abot.graph.stream({\"messages\": messages}, thread):\n",
    "    for v in event.values():\n",
    "        print(v['messages'])"
   ],
   "id": "ea8df587dc4c5c96"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langgraph.checkpoint.aiosqlite import AsyncSqliteSaver\n",
    "\n",
    "memory = AsyncSqliteSaver.from_conn_string(\":memory:\")\n",
    "abot = Agent(model, [tool], system=prompt, checkpointer=memory)\n",
    "\n",
    "messages = [HumanMessage(content=\"What is the weather in SF?\")]\n",
    "thread = {\"configurable\": {\"thread_id\": \"4\"}}\n",
    "async for event in abot.graph.astream_events({\"messages\": messages}, thread, version=\"v1\"):\n",
    "    kind = event[\"event\"]\n",
    "    if kind == \"on_chat_model_stream\":\n",
    "        content = event[\"data\"][\"chunk\"].content\n",
    "        if content:\n",
    "            # Empty content in the context of OpenAI means\n",
    "            # that the model is asking for a tool to be invoked.\n",
    "            # So we only print non-empty content\n",
    "            print(content, end=\"|\")"
   ],
   "id": "4cd2e0f717f926ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
